{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/frequencies_wolfram.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jakob\\Documents\\GitHub\\wordle_bot\\accessories\\word_probability.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jakob/Documents/GitHub/wordle_bot/accessories/word_probability.ipynb#ch0000001?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jakob/Documents/GitHub/wordle_bot/accessories/word_probability.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdata/frequencies_wolfram.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jakob/Documents/GitHub/wordle_bot/accessories/word_probability.ipynb#ch0000001?line=3'>4</a>\u001b[0m     freqs \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mreadlines()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jakob/Documents/GitHub/wordle_bot/accessories/word_probability.ipynb#ch0000001?line=5'>6</a>\u001b[0m freqs \u001b[39m=\u001b[39m freqs[\u001b[39m1\u001b[39m:]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/frequencies_wolfram.txt'"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "with open('data/frequencies_wolfram.txt', 'r') as f:\n",
    "    freqs = [i.strip() for i in f.readlines()]\n",
    "\n",
    "freqs = freqs[1:]\n",
    "\n",
    "with open('data/allowed_words.txt','r') as f:\n",
    "    words = [i.strip() for i in f.readlines()]\n",
    "    \n",
    "word_freq_dict = {}\n",
    "smallest = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The frequencies are in a strange form that Mathematica gives, so we need to convert them to a form that can be used in Python\n",
    "# For missing values I just used the smallest value.\n",
    "\n",
    "for ind, value in enumerate(freqs):\n",
    "    value = value.replace('*', '*10')\n",
    "    value = value.replace('^', '**')\n",
    "    try:\n",
    "        value = eval(value)\n",
    "        word_freq_dict[words[ind]] = value\n",
    "        if value < smallest:\n",
    "            smallest = value\n",
    "    except:\n",
    "        word_freq_dict[words[ind]] = -1\n",
    "\n",
    "\n",
    "for key, value in word_freq_dict.items():\n",
    "    if value == -1:\n",
    "        word_freq_dict[key] = smallest\n",
    "        \n",
    "# Scaling seemed like a good idea, IDK.\n",
    "values = np.array(list(word_freq_dict.values()))\n",
    "values = scale(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09200000000000007\n"
     ]
    }
   ],
   "source": [
    "# After manipulating the numbers a bit we put them through a sigmoid function.\n",
    "# So by manipulating i and j we set the steepness of the curve and the point where it will equal 0.5\n",
    "\n",
    "# Once the steepness was decided, i ran this because we know that there are about 2500 possible answers to wordle and it felt like a good number to use.\n",
    "\n",
    "i = 0\n",
    "j = 500\n",
    "while True:\n",
    "    values0 = (values + i) * j\n",
    "    s_values = 1/(1 + np.exp(-values0))\n",
    "    sorted_list = sorted(s_values, reverse=True)\n",
    "    if sorted_list[2500] > 0.5:\n",
    "        print(i)\n",
    "        break\n",
    "    i += 0.001\n",
    "\n",
    "# This was to manually check the probability scores of the words.\n",
    "cor_tups = [(k,v) for k,v in zip(words, s_values)]\n",
    "\n",
    "with open('data/frequencies_words_alpha.txt', 'w') as file:\n",
    "    for i in cor_tups:\n",
    "        file.write(i + '\\n')\n",
    "\n",
    "sorted_tups = sorted(cor_tups, key=lambda x: x[1], reverse=True)\n",
    "with open('data/frequencies_words_sorted.txt', 'w') as file:\n",
    "    for i in sorted_tups:\n",
    "        file.write(i + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_dict = {k: v for k,v in zip(words, s_values)}\n",
    "\n",
    "with open('data/word_probs.pkl', 'wb') as f:\n",
    "    pkl.dump(cor_dict, f)\n",
    "    \n",
    "# Maybe a pickle is faster to load?\n",
    "with open('data/allowed_words.pkl', 'wb') as f:\n",
    "    pkl.dump(words, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('wordle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34110caf40bf75e5d90f11e5809c7b6f34dd91dc2619c5800240501c65bd7bab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
